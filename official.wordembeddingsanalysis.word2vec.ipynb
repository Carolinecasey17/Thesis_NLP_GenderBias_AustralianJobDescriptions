{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import packages \"\"\"\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.utils import tokenize\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import re \n",
    "\n",
    "import string\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import the cleaned dataset and double check that it's dropped duplicates & na's \"\"\"\n",
    "\n",
    "data = pd.read_csv('data_cleaned_properly.csv', encoding='utf-8', converters={\"clean\": lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \")})\n",
    "df = data.drop_duplicates()\n",
    "df = data.dropna(how='any', subset=['Job Description'])\n",
    "df = data.dropna(how='any', subset=['clean'])\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape of dataframe \n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Gender Bias Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Function for creating gender bias dictionary with assigned gender bias values \"\"\"\n",
    "\n",
    "unique_words_dic = {}\n",
    "def calculate_gender_bias_dictionary(df_column, w2vmodel, word1, word2):\n",
    "#df_column = descriptions, w2vmodel = chosen model, word1 & word2 = gender identifiers \n",
    "        model = w2vmodel\n",
    "        male_word = word1\n",
    "        female_word = word2\n",
    "# Join all job descriptions\n",
    "        all_words = ' '.join(df_column)\n",
    "# Finds all unique words in the \"big word\"\n",
    "        unique_words = set(all_words.split(' '))\n",
    "# Create a dictionary with all unique words with gender bias values\n",
    "        for word in unique_words:\n",
    "            if word not in model.key_to_index.keys(): \n",
    "                unique_words_dic[word] = float(-1000.0) #assign -1000 if not in dictionary \n",
    "            else:\n",
    "                male_sim = float(w2vmodel.similarity(word, word1)) \n",
    "                female_sim = float(w2vmodel.similarity(word, word2)) \n",
    "                difference = male_sim - female_sim \n",
    "                unique_words_dic[word] = float(difference)\n",
    "        return unique_words_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Getting df_column to be  an indexed list of all unique words in dataset \"\"\"\n",
    "\n",
    "df_kol = data.clean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = ' '.join([str(word) for word in df_kol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_string = string1.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = new_string.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_column = list1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Specifying model and gender identifier vectors \"\"\"\n",
    "\n",
    "#model \n",
    "w2vmodel = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True, limit=500000)\n",
    "\n",
    "#speficy gender identifiers \n",
    "word1 = \"man\"\n",
    "word2 = \"woman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Calling the function \"\"\"\n",
    "\n",
    "gender_bias_dict = calculate_gender_bias_dictionary(df_column, w2vmodel, word1, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the type \n",
    "type(gender_bias_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Gender Bias per Job Description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Defining function that calculates average gender bias for each job description \"\"\"\n",
    "\n",
    "def calculate_gender_bias(posting, gender_bias_dict): \n",
    "    gender_bias_total = 0\n",
    "    #avg_gender_bias = 0\n",
    "    count = 0\n",
    "    #list_words = posting.split() \n",
    "    for word in posting:\n",
    "        bias = gender_bias_dict[word] \n",
    "        if bias != -1000.0:\n",
    "            gender_bias_total += bias \n",
    "            count += 1\n",
    "    return float((gender_bias_total / count) if count != 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias = []\n",
    "for i in df['clean']:\n",
    "    cal_bias = calculate_gender_bias(i, gender_bias_dict)\n",
    "    gender_bias.append(cal_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Finding mean of overall gender bias in data \"\"\" \n",
    "\n",
    "mean_bias = statistics.mean(gender_bias)\n",
    "print(mean_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Appending column to dataframe and saving as .csv for further analysis \"\"\" \n",
    "\n",
    "df[\"man_woman\"] = gender_bias\n",
    "\n",
    "#saving full dataframe as csv \n",
    "df.to_csv(\"dataset_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Extracting gender bias score for each word in gender bias dictionary and saving as .csv \"\"\" \n",
    "\n",
    "pd_bias = pd.DataFrame.from_dict(gender_bias_dict, orient='index')\n",
    "\n",
    "#save csv with gender scores \n",
    "pd_bias.to_csv(\"gender_bias_dict.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Analogies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = w2vmodel[\"computer_programmer\"] - w2vmodel[\"man\"] + w2vmodel[\"woman\"]\n",
    "w2vmodel.most_similar([vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = w2vmodel[\"king\"] - w2vmodel[\"man\"] + w2vmodel[\"woman\"]\n",
    "w2vmodel.most_similar([vec])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e24e9fa0c2d7de56cfe89077838e00512537972f092c8da3501dea7058d4d92"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
